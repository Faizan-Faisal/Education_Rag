# validator_tool.py

from pydantic import BaseModel, Field
from typing import Type
from crewai.tools import BaseTool
from crewai_rag.utils.custom_memory import CustomMemory  # ✅ Use your own memory system

# Input schema
class ValidationInput(BaseModel):
    question: str = Field(..., description="The student's original question.")
    subject: str = Field(..., description="The subject of the question.")
    generated_answer: str = Field(..., description="The answer generated by the LLM.")

class ValidatorTool(BaseTool):
    name: str = "validating"
    description: str = "Validates the answer using the retrieved context and ensures it’s accurate and well-structured."
    args_schema: Type[ValidationInput] = ValidationInput

    def _run(self, question: str, subject: str, generated_answer: str) -> str:
        # ✅ Use subject to target the correct memory file
        memory = CustomMemory(subject)
        context = memory.load("retrieved_context")

        if not context:
            return "No context found to validate the answer."

        prompt = f"""
You are a validation agent in a Retrieval-Augmented Generation (RAG) system for an LMS.

**Task:**
Validate the answer provided below for the student question.

**Student Question:** {question}
**Subject:** {subject}

**Generated Answer:**
{generated_answer}

**Retrieved Context:**
{context}

**Validation Goals:**
1. Ensure the answer is factually accurate.
2. Check if all relevant information from the context has been used.
3. Rewrite or enhance the answer to be clear, complete, and well-structured using proper headings and subheadings.

**Important:**
If the answer is already excellent, you may only format and rephrase it.
If it's incorrect or missing key points from the context, fix it.

**Final Validated Answer:**
"""

        return prompt
        memory.clear()  # Deletes the memory file for that subject
